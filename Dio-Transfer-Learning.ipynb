{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ay-tHHe9zdJd"
   },
   "source": [
    "1. Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1733252155649,
     "user": {
      "displayName": "Jean Moura",
      "userId": "07584647446128205886"
     },
     "user_tz": 180
    },
    "id": "zFzGyJUFzqYr"
   },
   "outputs": [],
   "source": [
    "# 1. Importação das bibliotecas necessárias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# montar drive no Google Colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de imagens de cachorros: 105\n",
      "Quantidade de imagens de raposas: 102\n"
     ]
    }
   ],
   "source": [
    "# contar arquivos na pasta dataset/dog e dataset/fox\n",
    "print('Quantidade de imagens de cachorros:', len(os.listdir('dataset/dog')))\n",
    "print('Quantidade de imagens de raposas:', len(os.listdir('dataset/fox')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Definição de parâmetros\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Parâmetros de divisão do dataset\n",
    "TRAIN_SPLIT = 0.7     # 70% para treino\n",
    "VAL_SPLIT = 0.15      # 15% para validação\n",
    "TEST_SPLIT = 0.15     # 15% para teste\n",
    "\n",
    "# Verificação de segurança para garantir que os splits somam 1\n",
    "assert abs(TRAIN_SPLIT + VAL_SPLIT + TEST_SPLIT - 1.0) < 1e-9, \"Os splits devem somar 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preparação dos dados\n",
    "def prepare_data(data_dir, train_split=TRAIN_SPLIT, val_split=VAL_SPLIT, test_split=TEST_SPLIT):\n",
    "    # Calculando o validation_split para o ImageDataGenerator\n",
    "    # Como o ImageDataGenerator divide apenas em dois conjuntos,\n",
    "    # precisamos ajustar o validation_split para obter as proporções corretas\n",
    "    validation_split = (val_split + test_split) / (train_split + val_split + test_split)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=validation_split\n",
    "    )\n",
    "\n",
    "    # Gerador para dados de teste (apenas rescale)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Carregar dados de treino\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='training',\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Carregar dados de validação e teste\n",
    "    temp_val_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='validation',\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Ajustar a proporção entre validação e teste\n",
    "    val_ratio = val_split / (val_split + test_split)\n",
    "    n_val = int(len(temp_val_generator.filenames) * val_ratio)\n",
    "    \n",
    "    # Criar geradores separados para validação e teste\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='validation',\n",
    "        seed=42,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    print(f\"\\nDivisão do dataset:\")\n",
    "    print(f\"Treino: {len(train_generator.filenames)} imagens ({train_split*100:.1f}%)\")\n",
    "    print(f\"Validação: {n_val} imagens ({val_split*100:.1f}%)\")\n",
    "    print(f\"Teste: {len(temp_val_generator.filenames) - n_val} imagens ({test_split*100:.1f}%)\")\n",
    "\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Criar o modelo com Transfer Learning\n",
    "def create_model():\n",
    "    # Carregar o modelo base MobileNetV2 pré-treinado\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    # Congelar as camadas do modelo base\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Criar o modelo completo\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        # 1 neurônio para classificação binária\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Treinar o modelo\n",
    "def train_model(model, train_generator, validation_generator):\n",
    "    # Compilar o modelo\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Treinar o modelo\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina e avalia uma Random Forest para comparação\n",
    "def train_random_forest(train_generator, test_generator):\n",
    "    \"\"\"\n",
    "    Treina e avalia uma Random Forest para comparação\n",
    "    \"\"\"\n",
    "    # Preparar dados para Random Forest\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for i in range(len(train_generator)):\n",
    "        batch_x, batch_y = train_generator[i]\n",
    "        X_train.extend(batch_x.reshape(batch_x.shape[0], -1))\n",
    "        y_train.extend(batch_y)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # Treinar Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Preparar dados de teste\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for i in range(len(test_generator)):\n",
    "        batch_x, batch_y = test_generator[i]\n",
    "        X_test.extend(batch_x.reshape(batch_x.shape[0], -1))\n",
    "        y_test.extend(batch_y)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Fazer predições\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calcular métricas\n",
    "    cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "    roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "    return {\n",
    "        'confusion_matrix': cm_rf,\n",
    "        'roc': (fpr_rf, tpr_rf, roc_auc_rf),\n",
    "        'report': classification_report(y_test, y_pred_rf, target_names=['Dog', 'Fox']),\n",
    "        'model': rf\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para visualização de resultados\n",
    "\n",
    "results_folder = 'results/'\n",
    "\n",
    "\n",
    "def plot_training_history(history, save_path=results_folder):\n",
    "    \"\"\"\n",
    "    Plota o histórico de treinamento com estilo aprimorado\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot Acurácia\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], color='#2ecc71',\n",
    "             label='Treino', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], color='#e74c3c',\n",
    "             label='Validação', linewidth=2)\n",
    "    plt.title('Acurácia do Modelo', fontsize=14, pad=15)\n",
    "    plt.xlabel('Época', fontsize=12)\n",
    "    plt.ylabel('Acurácia', fontsize=12)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot Perda\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], color='#2ecc71',\n",
    "             label='Treino', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], color='#e74c3c',\n",
    "             label='Validação', linewidth=2)\n",
    "    plt.title('Perda do Modelo', fontsize=14, pad=15)\n",
    "    plt.xlabel('Época', fontsize=12)\n",
    "    plt.ylabel('Perda', fontsize=12)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_confusion_matrix(cm, save_path=results_folder):\n",
    "    \"\"\"\n",
    "    Plota matriz de confusão estilizada\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    plt.title('Matriz de Confusão', fontsize=14, pad=15)\n",
    "    plt.colorbar()\n",
    "\n",
    "    classes = ['Dog', 'Fox']\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    # Adicionar valores na matriz\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.xlabel('Predito', fontsize=12)\n",
    "    plt.ylabel('Real', fontsize=12)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, save_path=results_folder):\n",
    "    \"\"\"\n",
    "    Plota curva ROC estilizada\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='#2ecc71', lw=2,\n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='#e74c3c', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.title('Curva ROC', fontsize=14, pad=15)\n",
    "    plt.xlabel('Taxa de Falsos Positivos', fontsize=12)\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos', fontsize=12)\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_models(cnn_results, rf_results, save_path=results_folder):\n",
    "    \"\"\"\n",
    "    Compara os resultados do CNN e Random Forest\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Plot ROC curves\n",
    "    plt.plot(cnn_results['roc'][0], cnn_results['roc'][1],\n",
    "             label=f'CNN (AUC = {cnn_results[\"roc\"][2]:.2f})',\n",
    "             color='#2ecc71', linewidth=2)\n",
    "    plt.plot(rf_results['roc'][0], rf_results['roc'][1],\n",
    "             label=f'Random Forest (AUC = {rf_results[\"roc\"][2]:.2f})',\n",
    "             color='#e74c3c', linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taxa de Falsos Positivos', fontsize=12)\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos', fontsize=12)\n",
    "    plt.title('Comparação das Curvas ROC', fontsize=14, pad=15)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra informações detalhadas sobre os conjuntos de dados\n",
    "\n",
    "def show_dataset_info(train_generator, val_generator, test_generator):\n",
    "    \"\"\"\n",
    "    Mostra informações detalhadas sobre os conjuntos de dados\n",
    "    \"\"\"\n",
    "    total_images = (len(train_generator.filenames) +\n",
    "                    len(val_generator.filenames) +\n",
    "                    len(test_generator.filenames))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"INFORMAÇÕES DO DATASET\".center(50))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(f\"\\nTotal de imagens: {total_images}\")\n",
    "\n",
    "    # Informações do conjunto de treino\n",
    "    print(\"\\n\" + \"-\"*20 + \" TREINO \" + \"-\"*20)\n",
    "    print(f\"Total: {len(train_generator.filenames)} imagens\")\n",
    "    print(f\"Proporção: {len(train_generator.filenames)/total_images:.1%}\")\n",
    "    class_dist = dict(zip(train_generator.class_indices.keys(),\n",
    "                          np.bincount(train_generator.classes)))\n",
    "    for cls, count in class_dist.items():\n",
    "        print(f\"{cls}: {count} imagens\")\n",
    "\n",
    "    # Informações do conjunto de validação\n",
    "    print(\"\\n\" + \"-\"*20 + \" VALIDAÇÃO \" + \"-\"*20)\n",
    "    print(f\"Total: {len(val_generator.filenames)} imagens\")\n",
    "    print(f\"Proporção: {len(val_generator.filenames)/total_images:.1%}\")\n",
    "    class_dist = dict(zip(val_generator.class_indices.keys(),\n",
    "                          np.bincount(val_generator.classes)))\n",
    "    for cls, count in class_dist.items():\n",
    "        print(f\"{cls}: {count} imagens\")\n",
    "\n",
    "    # Informações do conjunto de teste\n",
    "    print(\"\\n\" + \"-\"*20 + \" TESTE \" + \"-\"*20)\n",
    "    print(f\"Total: {len(test_generator.filenames)} imagens\")\n",
    "    print(f\"Proporção: {len(test_generator.filenames)/total_images:.1%}\")\n",
    "    class_dist = dict(zip(test_generator.class_indices.keys(),\n",
    "                          np.bincount(test_generator.classes)))\n",
    "    for cls, count in class_dist.items():\n",
    "        print(f\"{cls}: {count} imagens\")\n",
    "    print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliar o modelo\n",
    "def evaluate_model(model, test_generator):\n",
    "    \"\"\"\n",
    "    Avalia o modelo usando várias métricas\n",
    "    \"\"\"\n",
    "    # Fazer predições\n",
    "    predictions = model.predict(test_generator)\n",
    "    y_pred = (predictions > 0.5).astype(int)\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    # Calcular matriz de confusão\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Calcular ROC e AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Gerar relatório de classificação\n",
    "    report = classification_report(y_true, y_pred, target_names=['Dog', 'Fox'])\n",
    "\n",
    "    return {\n",
    "        'confusion_matrix': cm,\n",
    "        'roc': (fpr, tpr, roc_auc),\n",
    "        'report': report,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'predictions': predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Função principal\n",
    "def main(train_split=TRAIN_SPLIT, val_split=VAL_SPLIT, test_split=TEST_SPLIT):\n",
    "    # Definir o diretório dos dados\n",
    "    data_dir = 'dataset/'\n",
    "\n",
    "    # Preparar os dados com os splits especificados\n",
    "    train_generator, validation_generator, test_generator = prepare_data(\n",
    "        data_dir,\n",
    "        train_split=train_split,\n",
    "        val_split=val_split,\n",
    "        test_split=test_split\n",
    "    )\n",
    "    \n",
    "    # Mostrar informações do dataset\n",
    "    show_dataset_info(train_generator, validation_generator, test_generator)\n",
    "\n",
    "    # Criar o modelo\n",
    "    model = create_model()\n",
    "    history = train_model(model, train_generator, validation_generator)\n",
    "    \n",
    "    # Avaliar o modelo CNN\n",
    "    cnn_results = evaluate_model(model, test_generator)\n",
    "\n",
    "    # Treinar e avaliar Random Forest\n",
    "    # rf_results = train_random_forest(train_generator, test_generator)\n",
    "    \n",
    "    # Plotar resultados\n",
    "    plot_training_history(history, save_path='results/training_history.png')\n",
    "    plot_confusion_matrix(cnn_results['confusion_matrix'], save_path='results/cnn_confusion_matrix.png')\n",
    "    # plot_roc_curve(*cnn_results['roc'], save_path='cnn_roc_curve.png')\n",
    "    # compare_models(cnn_results, rf_results, save_path='model_comparison.png')\n",
    "    \n",
    "    # Imprimir relatórios de classificação\n",
    "    print(\"\\nRelatório de Classificação - CNN:\")\n",
    "    print(cnn_results['report'])\n",
    "    # print(\"\\nRelatório de Classificação - Random Forest:\")\n",
    "    # print(rf_results['report'])\n",
    "    \n",
    "    # # Avaliar no conjunto de teste\n",
    "    # test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    # print(f'\\nDesempenho no conjunto de teste:')\n",
    "    # print(f'Acurácia: {test_accuracy:.4f}')\n",
    "    # print(f'Loss: {test_loss:.4f}')\n",
    "\n",
    "    # # Plotar resultados\n",
    "    # plot_training_history(history)\n",
    "\n",
    "    # Salvar o modelo\n",
    "    model.save('models/dog_fox_classifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Função para predizer uma imagem\n",
    "def predict_image(image_path):\n",
    "    # Carregar o modelo salvo\n",
    "    model = tf.keras.models.load_model('models/dog_fox_classifier.keras')\n",
    "    \n",
    "    # Carregar e preprocessar a imagem\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0  # Normalização\n",
    "    \n",
    "    # Fazer a predição\n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    # Interpretar o resultado\n",
    "    # Como usamos classificação binária, valores próximos a 0 indicam a primeira classe (dog)\n",
    "    # e valores próximos a 1 indicam a segunda classe (fox)\n",
    "    class_names = ['dog', 'fox']\n",
    "    predicted_class = class_names[int(prediction[0] > 0.5)]\n",
    "    confidence = prediction[0] if prediction[0] > 0.5 else 1 - prediction[0]\n",
    "    \n",
    "    return predicted_class, float(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo com os splits padrão\n",
    "main(train_split=0.8, val_split=0.1, test_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list images in folder dataset/predict\n",
    "# images = os.listdir('dataset/predict')\n",
    "# images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fazer uma predição\n",
    "# image_path = 'raposa.jpg'\n",
    "# predicted_class, confidence = predict_image(image_path)\n",
    "\n",
    "# img = image.load_img(image_path)\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.title(f'Predição: {predicted_class} ({confidence:.2%})')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# print(f'Classe predita: {predicted_class}')\n",
    "# print(f'Confiança: {confidence:.2%}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMX++NYdbdz0nMRwSSbW7N8",
   "mount_file_id": "1yVMYPoreO8806AR5cEUL_I5zuFNTr6P4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
